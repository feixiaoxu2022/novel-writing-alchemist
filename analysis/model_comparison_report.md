# 小说写作能力模型横评报告

> **2026-02-18 | rev008 统一度量 | 8 模型 × 29 case（14 DSV1 + 15 DSV2）| 214 数据点**
>
> DSV1 和 DSV2 的相同 query 在不同 context 工程下视为独立 case。所有 case 合并后按模型聚合，评估模型在小说写作任务上的综合能力。
>
> 梯队划分沿用 DSV1 全量均分标准：≥75 强，≥50 中，<50 弱。

---

## Executive Summary

```
┌──────────────────────────────────────────────────────────────────────────┐
│  8 模型小说写作能力排名                                                   │
│                                                                          │
│  强梯队  claude-4.6 (88.6) > gemini-3-pro (83.4) > claude-4.5 (81.1)    │
│  中梯队  doubao-2.0-pro (74.8) > kimi-k2.5 (70.6) > qwen3-max (69.4)   │
│          > ernie-5.0 (53.1)                                              │
│  弱梯队  EB5-midtrain (40.2) ⚠️ gate 通过率仅 50%                      │
│                                                                          │
│  核心发现：                                                               │
│                                                                          │
│  1. 内容质量是决定性因素——流程好但内容差 ≠ 好模型                        │
│     kimi 流程 80.9 但内容仅 66.2（差距 -14.7），排名低于 doubao          │
│     EB5 流程 57.0 接近 ernie 的 57.4，但内容 33.0 vs 51.2，差距巨大     │
│                                                                          │
│  2. 强中弱梯队断层明显                                                    │
│     强梯队内容 84.3 vs 中梯队 64.7 vs 弱梯队 33.0                        │
│     Gate 通过率：强 100% > 中 97.1% > 弱 64.6%                           │
│     Advanced 通过率：强 79.1% > 中 51.9% > 弱 24.2%                      │
│                                                                          │
│  3. 模型的关键分化点：叙事密度、题材契合、角色语言辨识度                  │
│     这三项检查项的强弱模型差异最大（50~90pp）                              │
└──────────────────────────────────────────────────────────────────────────┘
```

---

## 一、分析设计

### 1.1 评价体系

```
                        ┌─────────────────────────────┐
                        │    总分 total (0-100)        │
                        │  = 内容×0.7 + 流程×0.3      │
                        └──────┬──────────────┬───────┘
                               │              │
              ─────────────────┘              └─────────────────
              │                                                │
   ┌──────────┴──────────┐                        ┌────────────┴────────────┐
   │   内容质量 (×0.7)    │                        │    流程规范 (×0.3)       │
   │   基准60分公式       │                        │    三维度通过率均值      │
   └──────────┬──────────┘                        └────────────┬────────────┘
              │                                                │
   ┌──────────┼──────────────────┐              ┌──────────────┼──────────────┐
   │          │                  │              │              │              │
┌──┴───┐  ┌───┴────┐  ┌─────┴─────┐     ┌──────┴──────┐ ┌────┴────┐ ┌──────┴──────┐
│ Gate │  │ Basic  │  │ Advanced  │     │ 格式合规    │ │业务规则 │ │ 记忆管理    │
│ 底线 │  │ 基础   │  │ 优秀      │     │ format      │ │bizrule  │ │ memory      │
│      │  │        │  │           │     │ compliance  │ │comply.  │ │ management  │
│fail→ │  │fail→   │  │pass→     │     └─────────────┘ └─────────┘ └─────────────┘
│每项-20│ │按比例扣│  │按比例加  │
│(致命) │  │(从60扣)│  │(最高到100)│
└──────┘  └────────┘  └──────────┘

评分流程：  60 ──gate fail──▶ 扣至底 ──basic fail──▶ 继续扣 ──adv pass──▶ 加至顶
            │                                                              │
            ▼                                                              ▼
        gate全fail → 0分                                          adv全pass → 100分
```

> **阅读指引**：后文"内容分"指内容质量维度得分，"流程分"指三项流程规范通过率的均值×100。Gate 是内容质量的生死线——章节克隆、交替重复、章节完整性任一触发，该样本内容分被大幅扣减（gate_triggered）。

### 1.2 Checker 如何读正文

检查项分两类执行方式，对正文的输入策略不同：

```
┌─────────────────────────────────────────────────────────────────────┐
│  程序化检查（Gate层 P0-P3 + Basic层 P4-P5）                          │
│  不调用 LLM，直接对文件做计算                                        │
│  · MD5 比对（章节克隆）                                              │
│  · 字节大小序列模式检测（交替重复）                                    │
│  · 文件计数 / 字数统计（章节完成度、篇幅控制）                         │
│  → 无截断问题，100% 精确                                             │
├─────────────────────────────────────────────────────────────────────┤
│  LLM Judge 检查（Basic/Advanced 层的语义类检查项）                    │
│  将全部章节文件按顺序拼接，一次性交给 LLM 评估                        │
│                                                                     │
│  输入拼接方式：                                                      │
│  chapter_01.md + chapter_02.md + ... + chapter_N.md                 │
│  部分检查项额外拼入 outline.json 或 characters.json                  │
│                                                                     │
│  长文本截断策略（超过 15 万字符时触发）：                              │
│  ┌──────────┬─────────────────────┬──────────┐                      │
│  │ 前 7.5 万 │  中间省略（标注字数） │ 后 7.5 万 │                      │
│  └──────────┴─────────────────────┴──────────┘                      │
│  保留开头章节 + 结尾章节，丢弃中间部分                                │
│                                                                     │
│  实测各篇幅正文长度：                                                │
│  · ULTRA_SHORT ≤ 8.2 万字符  → 不触发截断                           │
│  · SHORT       ≤ 8.1 万字符  → 不触发截断                           │
│  · MEDIUM      ≤ 15.3 万字符 → 极少数触发截断                       │
│  → 99% 的样本可全文送入 LLM，仅极端 MEDIUM 样本会丢失中间章节        │
└─────────────────────────────────────────────────────────────────────┘
```

> **影响**：截断只影响极端长篇的 LLM Judge 类检查，且保留了首尾章节（对"后期跑偏""反复结局""大纲执行忠实度"等重点关注首尾的检查项影响最小）。程序化检查（Gate层）始终基于完整文件，不受截断影响。

### 1.3 数据口径

- **29 个 case**：DSV1 有 14 个 task（4 MEDIUM + 4 SHORT + 1 IP_MEDIUM + 5 ULTRA_SHORT），DSV2 有 15 个 task（7 MEDIUM + 2 SHORT + 1 IP_MEDIUM + 5 ULTRA_SHORT），其中 11 个 query 共有。相同 query 在不同 context 工程下视为独立样本。
- **8 个模型**：3 个模型（EB5/kimi/qwen3）各 24 个样本（缺 DSV2 ultra_short），claude-4.6 28 个（排除 1 个零章节 error 样本），ernie 27 个（排除 2 个零章节 error 样本），其余 3 个模型各 29 个。共 214 个数据点。

### 1.4 梯队划分

| 梯队 | 模型 | 标准 |
|------|------|------|
| 强 | claude-4.6, gemini-3-pro, claude-4.5 | DSV1 全量均分 ≥75 |
| 中 | doubao-2.0-pro, kimi-k2.5, qwen3-max, ernie-5.0 | DSV1 全量均分 ≥50 |
| 弱 | EB5-midtrain | DSV1 全量均分 <50 |

### 1.5 关键前提：流程规范服务于内容交付

所有流程规范要求（skill 读取、SOP 遵从、日志管理、篇幅控制等）的最终目的是交付高质量的完整作品。**流程分高但内容差，说明"知道该怎么做但做不到"——这比"不知道该怎么做"更值得关注，因为它指向模型核心写作能力的瓶颈。**

---

## 二、模型总览

### 2.1 排名总表

| 排名 | 模型 | 梯队 | N | 总分 | 内容分 | 流程分 | 内容-流程差 | Gate Fail |
|------|------|------|---|------|--------|--------|-------------|-----------|
| 1 | claude-4.6 | 强 | 28 | **88.6** | **90.2** | 84.9 | +5.3 | 0 |
| 2 | gemini-3-pro | 强 | 29 | **83.4** | **84.2** | 81.6 | +2.6 | 0 |
| 3 | claude-4.5 | 强 | 29 | **81.1** | 78.7 | **86.8** | -8.1 | 0 |
| 4 | doubao-2.0-pro | 中 | 29 | 74.8 | 73.1 | 78.8 | -5.8 | 0 |
| 5 | kimi-k2.5 | 中 | 24 | 70.6 | 66.2 | 80.9 | **-14.7** | 0 |
| 6 | qwen3-max | 中 | 24 | 69.4 | 68.1 | 72.3 | -4.3 | 3 (12.5%) |
| 7 | ernie-5.0 | 中 | 27 | 53.1 | 51.2 | 57.4 | -6.2 | 3 (11.1%) |
| 8 | EB5-midtrain | 弱 | 24 | 40.2 | 33.0 | 57.0 | **-24.0** | 12 (50%) ⚠️ |

> 按总分排序。总分 = 内容×0.7 + 流程×0.3。

```
         总分分布
         0    20    40    60    80   100
         ├────┼─────┼─────┼─────┼────┤
claude-4.6    ·····················██████████████████▓  88.6
gemini-3-pro  ·····················███████████████▓   83.4
claude-4.5    ·····················██████████████▓    81.1
doubao-2.0    ·····················██████████▓        74.8
kimi-k2.5     ·····················████████▓          70.6
qwen3-max     ·····················███████▓           69.4
ernie-5.0     ·····················████▓              53.1
EB5-midtrain  ···············▓▓                       40.2
         ├────┼─────┼─────┼─────┼────┤
         0    20    40    60    80   100
```

### 2.2 总分分布（稳定性）

| 模型 | 均值 | 中位数 | 标准差 | 最低 | 最高 |
|------|------|--------|--------|------|------|
| claude-4.6 | 88.6 | 89.1 | 4.8 | 76.3 | 97.2 |
| gemini-3-pro | 83.4 | 83.8 | 5.7 | 72.5 | 98.3 |
| claude-4.5 | 81.1 | 80.5 | 7.0 | 63.7 | 95.5 |
| doubao-2.0-pro | 74.8 | 75.5 | 8.9 | 55.9 | 91.8 |
| kimi-k2.5 | 70.6 | 71.0 | 9.3 | 51.4 | 85.9 |
| qwen3-max | 69.4 | 70.0 | 5.3 | 60.3 | 77.6 |
| ernie-5.0 | 53.1 | 56.5 | 16.3 | 13.8 | 79.1 |
| EB5-midtrain | 40.2 | 43.5 | 25.2 | 0.0 | 76.2 |

关键观察：

- **gemini-3-pro 最稳定**（标准差 5.7），最低分 72.5 仍处于合格水平，没有崩溃样本
- **qwen3-max 也很稳定**（标准差 5.3），但天花板低（最高仅 77.6）
- **claude-4.6 也很稳定**（标准差 4.8），最低分 76.3，零 gate fail，中位数 89.1 是所有模型最高
- **ernie 和 EB5 波动最大**（标准差 16+25），质量极不稳定

### 2.3 分数段分布

| 模型 | <30 | 30-50 | 50-70 | 70-85 | ≥85 | 优秀率(≥85) |
|------|-----|-------|-------|-------|-----|------------|
| claude-4.6 | 0 | 0 | 0 | 7 | **21** | **75%** |
| gemini-3-pro | 0 | 0 | 0 | 18 | **11** | 38% |
| claude-4.5 | 0 | 0 | 2 | 18 | **9** | 31% |
| doubao-2.0-pro | 0 | 0 | 7 | 17 | 5 | 17% |
| kimi-k2.5 | 0 | 0 | 11 | 12 | 1 | 4% |
| qwen3-max | 0 | 0 | 12 | 12 | 0 | 0% |
| ernie-5.0 | 4 | 5 | 15 | 3 | 0 | 0% |
| EB5-midtrain | 9 | 4 | 8 | 3 | 0 | 0% |

- **claude-4.6 优秀率遥遥领先**（75%），3/4 的样本达到 85 分以上
- **强梯队全部有 ≥85 的样本**，中梯队中仅 doubao 和 kimi 有少量
- **ernie/qwen3/EB5 无一达到优秀**，其中 ernie 和 EB5 还有大量 <50 的崩溃样本

### 2.4 内容与流程的关系

| 模型 | 内容分 | 流程分 | 差值(C-P) | 流程>70但内容<50 |
|------|--------|--------|-----------|-----------------|
| claude-4.6 | 90.2 | 84.9 | **+5.3** | 0 |
| gemini-3-pro | 84.2 | 81.6 | +2.6 | 0 |
| claude-4.5 | 78.7 | 86.8 | -8.1 | 0 |
| doubao-2.0-pro | 73.1 | 78.8 | -5.8 | 1 |
| qwen3-max | 68.1 | 72.3 | -4.3 | 1 |
| kimi-k2.5 | 66.2 | 80.9 | **-14.7** | **3** |
| ernie-5.0 | 51.2 | 57.4 | -6.2 | **7** |
| EB5-midtrain | 33.0 | 57.0 | **-24.0** | **4** |

**"流程好但内容差"现象分析**：

- **kimi 是最典型的"知道怎么做但做不到"型**：流程分 80.9（排第4，高于 doubao），但内容仅 66.2，差距 -14.7 是除 EB5 外最大的。有 3 个样本流程>70 但内容<50。这意味着 kimi 能正确读取 skill 文件、遵循 SOP、管理日志，但最终写出的小说质量不行。
- **EB5 的 C-P 差距 -24.0 最极端**：但其流程分 57.0 本身也不高，说明两方面都有严重问题——只是内容问题更严重。
- **claude-4.6 和 gemini 是唯二内容>流程的模型**：说明强模型的写作能力超过了评测体系对流程的要求。特别是 claude-4.6 的 +5.3 差值说明其核心创作能力非常强。

---

## 三、内容质量深入分析

> **内容分 = 最终交付的小说质量。三层结构：Gate（底线）→ Basic（基础）→ Advanced（优秀）。**

### 3.1 三层通过率

| 模型 | Gate 层 | Basic 层 | Advanced 层 | 内容均分 |
|------|---------|----------|-------------|----------|
| claude-4.6 | **100.0%** | **92.7%** | **86.4%** | **90.2** |
| gemini-3-pro | **100.0%** | 89.1% | 76.9% | 84.2 |
| claude-4.5 | **100.0%** | 81.8% | 74.1% | 78.7 |
| doubao-2.0-pro | **100.0%** | 81.8% | 60.0% | 73.1 |
| qwen3-max | 93.8% | 82.7% | 52.5% | 68.1 |
| kimi-k2.5 | **100.0%** | 72.0% | 57.5% | 66.2 |
| ernie-5.0 | 94.4% | 62.9% | 37.8% | 51.2 |
| EB5-midtrain | 64.6% | 49.5% | 24.2% | 33.0 |

```
         Gate 层        Basic 层       Advanced 层
         ├────────────┤├────────────┤├────────────┤
claude-4.6    █████████████ 100  █████████████ 92.7  ████████████ 86.4
gemini-3-pro  █████████████ 100  ████████████ 89.1  ██████████▓  76.9
claude-4.5    █████████████ 100  ███████████▓ 81.8  █████████▓   74.1
doubao-2.0    █████████████ 100  ███████████▓ 81.8  ████████▓    60.0
qwen3-max     ████████████ 93.8  ███████████▓ 82.7  ███████▓     52.5
kimi-k2.5     █████████████ 100  █████████▓   72.0  ███████▓     57.5
ernie-5.0     ████████████ 94.4  ████████▓    62.9  █████▓       37.8
EB5-midtrain  ████████▓    64.6  ██████▓      49.5  ████▓        24.2
```

**梯队特征**：

| 指标 | 强梯队 | 中梯队 | 弱梯队 |
|------|--------|--------|--------|
| Gate 通过率 | 100.0% | 97.1% | 64.6% |
| Basic 通过率 | 87.8% | 74.8% | 49.5% |
| Advanced 通过率 | **79.1%** | 51.9% | 24.2% |
| 内容均分 | **84.3** | 64.7 | 33.0 |

- **Gate 层**：强梯队和中梯队差异不大（100% vs 97.1%），多数模型能完成基本的章节输出。弱梯队（EB5）64.6% 说明一半样本连章节文件都输出不了。
- **Basic 层是第一个分水岭**：强 87.8% vs 中 74.8%——角色落地、叙事密度、情节逻辑等基础写作能力拉开差距。
- **Advanced 层是关键分化点**：强 79.1% vs 中 51.9%——节奏把控、意象系统、钩子设计等高阶能力差距进一步扩大到 27pp。

### 3.2 Gate 层——底线能力

Gate 层包含 4 个"一票否决"检查项。任一 fail 则 gate_triggered，内容分被严重扣减。下表为各项 **通过率**（越高越好）：

| 检查项 | 含义 | claude-4.6 | gemini | claude-4.5 | doubao | qwen3 | kimi | ernie | EB5 |
|--------|------|-----------|--------|-----------|--------|-------|------|-------|-----|
| chapter_output_existence | 工作区里至少有一个章节文件产出 | 100% | 100% | 100% | 100% | 100% | 100% | 100% | **70.8%** |
| chapter_cloning | 没有连续≥2章内容完全一样（去标题后MD5比对） | 100% | 100% | 100% | 100% | 100% | 100% | **90.0%** | **56.5%** |
| alternating_repetition | 后半部分没有出现≥3轮A-B-A-B交替循环的章节 | 100% | 100% | 100% | 100% | 100% | 100% | **94.1%** | **65.2%** |
| chapter_completion | 实际写的章节数 ≥ 大纲规划章节数的30% | 100% | 100% | 100% | 100% | 87.5% | 100% | **91.3%** | **66.7%** |

- **强梯队 + doubao + kimi**：Gate 层完美，全部 100% 通过。
- **qwen3**：chapter_completion 87.5%——有少量样本在写作过程中未完成所有章节。
- **ernie**：chapter_cloning（90.0%）、chapter_completion（91.3%）和 alternating_repetition（94.1%）未达 100%——模型在长篇写作中出现章节克隆和未完成章节的问题。
- **EB5**：四项全面崩溃，chapter_cloning 仅 56.5% 说明近半数样本出现了重复章节内容。根因是模型不会使用 write_file 工具。

### 3.3 Basic 层——基础写作能力

> 下表为各检查项的 **通过率**（越高越好）。"强弱差"= 强均通过率 − EB5 通过率。

| 检查项 | 强均 | 中均 | EB5 | 说明 | 强弱差 |
|--------|------|------|-----|------|--------|
| dialogue_character_distinction | 42.0% | 7.5% | 4.2% | 遮住角色名还能分辨谁在说话（语气、用词有区别） | **37.8pp** |
| narrative_density | 90.8% | 41.6% | 12.5% | 有场景描写、感官细节、心理活动，不是干巴巴的事件罗列 | **78.3pp** |
| genre_fit | 73.6% | 17.5% | 4.2% | 题材特征写得有深度而非流于表面（如甜宠真的甜出层次、悬疑真的有推理深度） | **69.4pp** |
| outline_execution_fidelity | 66.5% | 48.7% | 33.3% | 正文内容忠实于自己设计的大纲，没有大纲写A结局正文写B结局 | **33.2pp** |
| structural_logic_defect | 58.3% | 45.0% | 16.7% | 没有时间线矛盾、人物凭空消失、世界观规则冲突等硬伤 | **41.6pp** |
| narrative_tone_match | 64.1% | 45.0% | 45.8% | 文笔风格和叙事语气与题材匹配（如烧脑文不能写成言情调） | 18.3pp |
| late_stage_digression | 84.9% | 66.2% | 37.5% | 后期章节没有混入作者感想、读者互动、番外预告等非正文内容 | **47.4pp** |
| character_design_adherence | 91.4% | 74.0% | 69.2% | 正文中角色的实际表现符合characters.json里的设计 | 22.2pp |
| repeated_endings | 97.7% | 89.5% | 66.7% | 全文只有一个结局，没有反复出现"全文完/全书完/后记" | **31.0pp** |

**模型分化最大的三项**（强弱差 >50pp）：

1. **narrative_density（叙事密度）**：强 90.8% vs 中 41.6% vs EB5 12.5%。这是模型间差异最大的单项检查。强模型能写出有细节、有画面感、有张力的叙事；中等模型则倾向于"流水账"式叙述。
2. **genre_fit（题材契合度）**：强 73.6% vs 中 17.5%。强模型能把悬疑写出悬疑味、甜宠写出甜蜜感；中等模型的产出往往"四不像"，不同题材写出来差异不大。
3. **late_stage_digression（无后期跑偏）**：强 84.9% vs 中 66.2% vs EB5 37.5%。越弱的模型越容易在后半段偏离主线，引入无关情节。

**模型间独特表现**：

- **claude-4.6 在 narrative_density（96.4%）和 genre_fit（100%）上接近完美**——这是其内容分领先的核心原因
- **kimi 的 late_stage_digression 仅 37.5% 通过**——远低于中梯队平均（66.2%），是 kimi 内容分偏低的重要原因
- **fixable_logic_inconsistency 全员低通过**（0%~33.3%）——小瑕疵几乎不可避免，属于天花板效应

### 3.4 Advanced 层——高阶写作能力

> 下表为各检查项的 **通过率**（越高越好）。

| 检查项 | 强均 | 中均 | EB5 | 说明 |
|--------|------|------|-----|------|
| pacing_rationality_advanced | 94.3% | 50.4% | 16.7% | 起承转合节奏自然，有铺垫有高潮有收束，不拖沓不仓促 |
| hook_design | 98.9% | 81.4% | 25.0% | 关键转折处有具体、有信息差的悬念钩子，不是空洞的"接下来会如何" |
| imagery_system | 100.0% | 90.8% | 45.8% | 有一个反复出现的具体物件/场景，且每次出现含义随剧情变化（如"信"从恶作剧→警告→遗书→闭环） |
| structural_design | 98.9% | 84.6% | 41.7% | 叙事结构有设计感（如首尾呼应、视角切换、非线性时间线） |
| emotional_gradient | 98.9% | 89.6% | 37.5% | 主角情感有≥4层性质不同的变化，每次转折由具体事件驱动 |
| emotional_delivery_match | 89.8% | 75.5% | 44.0% | 情感交付到位（如虐文真的虐到心、甜文真的甜到齁） |
| semantic_redundancy | 58.3% | 17.5% | 4.2% | 后续章节没有在语义层面大量重复前文已说过的内容（≥3处即fail） |

**Advanced 层揭示了真正的"创作才华"分水岭**：

- **pacing_rationality_advanced**：强 94.3% vs 中 50.4%——差距 44pp。节奏把控需要对"紧张→松弛→高潮"的全局掌控，这是强模型独有的能力。
- **hook_design / imagery_system / structural_design**：强梯队接近完美（98.9~100%），中梯队 81~91% 通过，EB5 不足半数通过。
- **semantic_redundancy 是全员短板**：强梯队也仅 58.3% 通过——说明 AI 生成文本的"重复感"是一个系统性难题，即使强模型也难以完全避免。

### 3.5 按篇幅的内容表现

| 模型 | MEDIUM 内容 | SHORT 内容 | ULTRA_SHORT 内容 |
|------|------------|------------|------------------|
| claude-4.6 | 88.9 | **90.6** | **91.4** |
| gemini-3-pro | 81.6 | 86.1 | 85.9 |
| claude-4.5 | 74.5 | 77.8 | 84.4 |
| doubao-2.0-pro | 64.5 | 73.9 | 82.8 |
| qwen3-max | 61.3 | 75.4 | 74.2 |
| kimi-k2.5 | 58.2 | 71.3 | 78.2 |
| ernie-5.0 | 40.5 | 56.8 | 60.0 |
| EB5-midtrain | 17.0 | 46.0 | 53.0 |

**一致规律：所有模型在 MEDIUM（中篇）上的内容分最低。** 篇幅越长，对角色管理、情节连贯性、节奏控制的要求越高，模型能力差异被放大。

- **MEDIUM 是最具区分度的篇幅**：强梯队均分 81.7 vs 中梯队 56.1 vs EB5 17.0——梯队间差距在 MEDIUM 上最显著
- **ULTRA_SHORT 差距最小**：强 87.2 vs 中 73.4 vs EB5 53.0——短篇幅下模型都能写出相对完整的作品
- **EB5 在 MEDIUM 上近乎零分（17.0）**：主要因为 gate 通过率在 MEDIUM 上最低

---

## 四、流程规范分析

> **再次强调：流程规范的目的是交付高质量作品。本节数据需结合第三节内容质量一起看。**

### 4.1 三维度通过率

| 模型 | 格式合规 | 业务规则合规 | 记忆管理 | 流程均分 |
|------|---------|-------------|---------|---------|
| claude-4.5 | 88.8% | 84.7% | **70.7%** | **86.8** |
| claude-4.6 | **94.6%** | **84.5%** | 58.9% | 84.9 |
| gemini-3-pro | **98.3%** | **86.2%** | 43.1% | 81.6 |
| kimi-k2.5 | 83.3% | 76.0% | **83.3%** | 80.9 |
| doubao-2.0-pro | 94.0% | 78.8% | 34.5% | 78.8 |
| qwen3-max | **97.9%** | 81.6% | 37.5% | 72.3 |
| ernie-5.0 | 70.4% | 61.3% | 37.0% | 57.4 |
| EB5-midtrain | 72.9% | 56.3% | 41.7% | 57.0 |

**记忆管理是最大的分化维度**：

- kimi（83.3%）和 claude-4.5（70.7%）在记忆管理上领先——这两个模型擅长在多轮交互中保持上下文一致性
- gemini（43.1%）和 doubao（34.5%）相对较弱——gemini 的格式合规（98.3%）和业务规则（86.2%）都很高，但记忆管理拖了后腿
- 值得注意的是 **kimi 的记忆管理 83.3% 是中梯队最高**，远超同梯队的 doubao（34.5%）和 qwen3（37.5%）

### 4.2 关键流程检查项

> 下表为各检查项的 **通过率**（越高越好）。

| 检查项 | 强均 | 中均 | EB5 | 说明 |
|--------|------|------|-----|------|
| required_skill_reading | 76.3% | 72.0% | 51.6% | 动手写之前读了写作指南、命名规范、一致性管理等skill文件 |
| sop_compliance | 75.2% | 78.8% | 51.0% | 按规定流程走：配方选择→写作准备确认→再动笔 |
| log_file_usage | 43.7% | 41.2% | 4.2% | 写作过程中读取writing_log.md了解前文内容 |
| log_file_creation | 95.8% | 66.2% | 79.2% | 创建了writing_log.md记录创作进度 |
| range_constraint | 31.3% | 15.3% | 4.2% | **每章字数落在规定范围内** |
| quantity_constraint | 99.4% | 82.3% | 62.5% | Y轴标签数量(2-3个)、forbidden_elements(≥1个)等数值约束 |
| enum_validity | 99.4% | 81.1% | 68.8% | X轴模式ID格式、Y轴标签等选项值在允许的枚举列表内 |
| language_purity | 100.0% | 71.8% | 66.7% | 中文写作不无故夹杂英文（人名/品牌/角色设定除外） |

**篇幅控制（range_constraint）是全员最弱的流程项**：

- **强梯队也只有 31.3% 通过**——这说明篇幅控制是一个系统性难题
- 中梯队更差（仅 15.3% 通过），EB5 几乎全军覆没（4.2%）
- 这意味着大多数模型无法准确控制输出字数到指定范围

**log_file_usage 也是全员痛点**（强梯队仅 43.7% 通过）：模型创建了日志文件但不会有效使用它来记录写作进度和决策。

---

## 五、模型分梯队详解

### 5.1 强梯队——claude-4.6, gemini-3-pro, claude-4.5

| 指标 | claude-4.6 | gemini-3-pro | claude-4.5 |
|------|-----------|-------------|-----------|
| 总分 | **88.6** | 83.4 | 81.1 |
| 内容分 | **90.2** | **84.2** | 78.7 |
| 流程分 | 84.9 | 81.6 | **86.8** |
| 优秀率(≥85) | **75%** | 38% | 31% |
| 稳定性(σ) | **4.8** | 5.7 | 7.0 |
| Gate fail | 0 | 0 | 0 |

**强梯队内部分化**：

- **claude-4.6 是内容之王**：narrative_density 96.4%、genre_fit 100%、pacing 100% 均为全场最佳。75% 优秀率远超其他模型。零 gate fail，标准差仅 4.8（强梯队最稳定）。
- **gemini-3-pro 最稳定可靠**：标准差仅 5.7，最低分 72.5 仍然合格。无任何 gate fail。内容和流程均衡（84.2 vs 81.6）。genre_fit 51.7% 是其相对短板。
- **claude-4.5 流程规范最强**：流程分 86.8 全场第一。但内容分 78.7 在强梯队内最低——说明 claude-4.5 更擅长"遵循规范"而非"创作发挥"。semantic_redundancy 仅 24.1% 通过是其最突出的内容短板。

### 5.2 中梯队——doubao, qwen3, kimi, ernie

| 指标 | doubao | kimi | qwen3 | ernie |
|------|--------|------|-------|-------|
| 总分 | **74.8** | 70.6 | 69.4 | 53.1 |
| 内容分 | **73.1** | 66.2 | 68.1 | 51.2 |
| 流程分 | 78.8 | **80.9** | 72.3 | 57.4 |
| C-P 差 | -5.8 | **-14.7** | -4.3 | -6.2 |
| Gate fail | 0 | 0 | 3(12.5%) | 3(11.1%) |

**中梯队的四种模式**：

1. **doubao——最均衡的中等模型**：内容和流程都在中等水平，0 gate fail，质量稳定。quantity_constraint（55.2%）和 enum_validity（55.2%）是其独有短板。
2. **kimi——"优秀的助手，平庸的作家"**：流程分 80.9 接近强梯队水平，但内容仅 66.2——C-P 差值 -14.7 是所有模型中最大的。late_stage_digression 仅 37.5% 通过和 dialogue_character_distinction 0%（全部 fail）暴露了写作能力的硬伤。
3. **qwen3——"高方差的理论派"**：sop_compliance 较好（77.6%），但 chapter_completion 87.5% 说明执行中会中途放弃。内容分跨度大（narrative_density 仅 33.3% 通过）。
4. **ernie——"中梯队的底部"**：总分 53.1。chapter_cloning 90.0% 说明仍有一成样本出现章节内容重复的问题。character_design_adherence 52.0% 是全场最差——设计的角色在正文中无法贯彻。

### 5.3 弱梯队——EB5-midtrain ⚠️

| 指标 | EB5-midtrain | 说明 |
|------|-------------|------|
| 总分 | 40.2 | |
| 内容分 | 33.0 | |
| 流程分 | 57.0 | 接近 ernie 的 57.4 |
| Gate fail | **12 (50%)** | 半数样本连底线都过不了 |
| 排除 gate 后均分 | 59.1 | 勉强到 ernie 水平 |

EB5 的核心问题是**模型能力不足以完成基本的工具调用**：

- chapter_output_existence 仅 70.8%——近三成样本不输出章节文件
- chapter_cloning 仅 56.5%——输出的章节近半是重复的
- 即使排除 gate fail 后，剩余 12 个样本的均分也仅 59.1——说明即使"跑通"了，写出的内容质量也很差

---

## 六、关键检查项模型热力图

> 按通过率从高（好）到低（差）排列。深色 = 低通过率 = 差。

### 6.1 内容维度——强弱分化最大的检查项

> 检查项对照：narrative_density=有场景描写和感官细节而非事件罗列 | genre_fit=题材特征有深度而非流于表面 | pacing_rationality_adv=起承转合节奏自然不拖沓 | late_stage_digression=后期没混入非正文内容 | semantic_redundancy=后续章节没有语义重复前文 | dialogue_char_distinction=遮住名字能分辨谁在说话 | outline_exec_fidelity=正文忠实于自己设计的大纲 | structural_logic_defect=无时间线/世界观等逻辑硬伤

```
                           claude claude gemini doubao  kimi  qwen3 ernie  EB5
                            -4.6   -4.5  -3-pro  -2.0  -k2.5  -max  -5.0 -mid
  ─────────────────────────────────────────────────────────────────────────────
  narrative_density         █96.4 █79.3  █96.6  ▓58.6  ▒41.7  ▒33.3 ▒34.8 ░12.5
  genre_fit                 █100  ▓69.0  ▓51.7  ▒20.7  ▒37.5  ░ 4.2 ░ 8.7 ░ 4.2
  pacing_rationality_adv    █100  █93.1  █89.7  ▓65.5  ▓54.2  ▓62.5 ▒21.7 ░16.7
  late_stage_digression     █89.3 ▓72.4  █93.1  █79.3  ▒37.5  █100  ▓52.2 ▒37.5
  semantic_redundancy       ▓75.0 ▒24.1  ▓75.9  ▒37.9  ░ 8.3  ░12.5 ░ 8.7 ░ 4.2
  dialogue_char_distinction ▓53.6 ▒27.6  ▒44.8  ░13.8  ░ 0.0  ░ 4.2 ░13.0 ░ 4.2
  outline_exec_fidelity     █89.3 ▒44.8  ▓65.5  ▓58.6  ▒45.8  ▓62.5 ▒30.4 ▒33.3
  structural_logic_defect   ▓75.0 ▒44.8  ▓55.2  ▓65.5  ▒37.5  ▒45.8 ▒33.3 ░16.7
  ─────────────────────────────────────────────────────────────────────────────
  █ >80%   ▓ 60~80%   ▒ 20~60%   ░ <20%
```

### 6.2 流程维度——全员痛点 vs 模型差异

> 检查项对照：range_constraint=每章字数在规定范围内 | log_file_usage=读取writing_log了解前文 | required_skill_reading=读了写作指南等skill文件 | sop_compliance=按配方选择→确认→动笔的流程走 | language_purity=中文不无故夹英文 | quantity_constraint=标签数量等数值约束 | enum_validity=选项值在枚举列表内

```
                           claude claude gemini doubao  kimi  qwen3 ernie  EB5
                            -4.6   -4.5  -3-pro  -2.0  -k2.5  -max  -5.0 -mid
  ─────────────────────────────────────────────────────────────────────────────
  range_constraint          ▒21.4  ▒41.4  ▒31.0  ▒24.1  ░ 8.3  ░16.7 ░13.0 ░ 4.2
  log_file_usage            ▒43.5  ▓70.8  ░16.7  ▒31.6  ▓66.7  ▒33.3 ▒36.4 ░ 4.2
  required_skill_reading    ▓75.9  ▓74.5  ▓78.4  █85.2  ▓66.7  ▓75.8 ▓62.5 ▒51.6
  sop_compliance            ▓76.6  ▓71.4  ▓77.6  █94.9  ▓67.3  ▓77.6 ▓77.8 ▒51.0
  language_purity           █100   █100   █100   █89.7  ▒41.7  █95.8 ▓65.2 ▓66.7
  quantity_constraint       █100   █100   █98.3  ▓55.2  █91.3  █97.7 █84.2 ▓62.5
  enum_validity             █100   █98.3  █100   ▓55.2  █91.3  █95.5 █84.2 ▓68.8
  ─────────────────────────────────────────────────────────────────────────────
  █ >80%   ▓ 60~80%   ▒ 20~60%   ░ <20%
```

**解读**：

- **range_constraint 是无差别难题**：即使 claude-4.5（最佳，41.4% 通过）也不足半数达标。这不是模型能力问题，而是 AI 生成文本在字数精确控制上的系统性局限。
- **language_purity**：kimi 仅 41.7% 通过是突出的异常——kimi 在中文写作中混入大量英文术语或不自然表达。
- **quantity_constraint 和 enum_validity**：doubao 仅 55.2% 通过，远低于其他模型——这是 doubao 在结构化输出上的独有弱点。

---

## 七、结论

### 模型能力排名（最终结论）

```
  能力等级    模型              总分    核心特征
  ────────────────────────────────────────────────────────────────
  S 级        claude-4.6        88.6    内容之王，创作才华最强
  A 级        gemini-3-pro      83.4    最稳定，无崩溃样本
              claude-4.5        81.1    流程规范最强，内容略逊
  B 级        doubao-2.0-pro    74.8    中等均衡，结构化输出有弱点
              kimi-k2.5         70.6    流程好但写不出好内容
              qwen3-max         69.4    稳定但天花板低
  C 级        ernie-5.0         53.1    不稳定，gate 通过率 89%
  D 级        EB5-midtrain      40.2    基本工具调用都成问题
```

### 模型的核心优劣势

| 模型 | 最强项 | 最弱项 |
|------|--------|--------|
| claude-4.6 | 叙事密度(96.4%)、题材契合(100%)、节奏控制(100%) | 篇幅控制(21.4%)、日志使用(43.5%) |
| gemini-3-pro | 零 gate fail、稳定性(σ=5.7) | 日志使用(16.7%)、genre_fit(51.7%) |
| claude-4.5 | 流程分最高(86.8)、记忆管理(70.7%) | 语义重复(24.1%)、大纲执行(44.8%) |
| doubao-2.0-pro | 均衡无短板、SOP 遵从(94.9%) | 数量/枚举约束(55.2%)、genre_fit(20.7%) |
| kimi-k2.5 | 记忆管理(83.3%)、日志创建(100%) | 后期跑偏(37.5%)、对话辨识度(0%)、语言纯净(41.7%) |
| qwen3-max | 格式合规(97.9%)、稳定(σ=5.3) | 叙事密度(33.3%)、语义重复(12.5%)、天花板低(max=77.6) |
| ernie-5.0 | — | 全面偏弱，gate 通过率 88.9%，角色一致性(52.0%)最差 |
| EB5-midtrain | — | 基本工具调用失败，gate 通过率仅 50% |

### 三个关键发现

1. **内容质量决定排名，流程规范是必要非充分条件**。kimi 流程分 80.9（排第4）但总分只排第5，因为内容仅 66.2。EB5 流程分（57.0）接近 ernie（57.4），但总分差 13 分——全因内容差距（33.0 vs 51.2）。
2. **叙事密度、题材契合、角色语言辨识度是模型间差异最大的能力维度**。这三项的强弱模型差距在 50~90pp——远超其他检查项。要提升模型小说写作能力，应优先攻克这三个方向。
3. **篇幅越长，模型差距越大**。MEDIUM 上强梯队内容均分 81.7 vs 中梯队 56.1（差 26），但 ULTRA_SHORT 上差距缩小到 87.2 vs 73.4（差 14）。中篇写作对角色管理、情节连贯性、节奏控制的要求更高，是最能区分模型能力的测试场景。

---

## 附录

<details>
<summary>A. 数据来源与方法</summary>

- **数据提取**：`analysis/extract_rev006_data.py --revision 008`
- **原始数据**：`analysis/rev008_all_data.json`（214 条记录，8 模型）
- **分析脚本**：`analysis/analyze_model_comparison.py --revision 008`
- **分析输出**：`analysis/model_comparison_output.json`
- **29 个 case**：
  - DSV1（14）：4 MEDIUM + 4 SHORT + 1 IP_MEDIUM + 5 ULTRA_SHORT
  - DSV2（15）：7 MEDIUM + 2 SHORT + 1 IP_MEDIUM + 5 ULTRA_SHORT（含 VAGUE_MEDIUM）
  - 共有 11 个 query，但 context 工程不同，视为独立样本
- **样本数**：gemini/claude-4.5/doubao 各 29；claude-4.6 28（排除 1 个零章节 error）；ernie 27（排除 2 个零章节 error）；EB5/kimi/qwen3 各 24（缺 DSV2 ultra_short）
- **评分公式**：total = content×0.7 + process×0.3
- **梯队标准**：DSV1 全量均分 ≥75 强，≥50 中，<50 弱
- **数据清洗**：排除 `execution_status=error` 且工作区无 chapter 文件（`chapter_*.md`）的样本——3 个被排除：claude-4.6 dsv2 HEROINE_001（API 超时）、ernie dsv1 SUSPENSE_001、ernie dsv1 US_ANGSTY_004

</details>

<details>
<summary>B. 检查项分类说明</summary>

**内容质量三层结构**：

- **Gate 层**（4 项，一票否决）：
  - chapter_output_existence（工作区至少有一个章节文件产出）
  - chapter_cloning（没有连续≥2章内容完全克隆）
  - alternating_repetition（后半部分没有≥3轮A-B交替循环）
  - chapter_completion（实际章节数 ≥ 大纲规划的30%）
- **Basic 层**（~16 项）：角色设计一致性、对话辨识度、叙事密度、题材契合、大纲执行、逻辑缺陷、后期跑偏、反复结局等
- **Advanced 层**（~10 项）：节奏控制、钩子设计、意象系统、结构设计、情绪层次、语义重复等

**流程三维度**：

- **格式合规**：命名规范、结构完整性、枚举值合法性、数量约束
- **业务规则合规**：SOP 遵从、skill 读取、日志管理、篇幅控制、主题一致性、角色一致性、语言纯净度
- **记忆管理**：log_file_creation（日志文件创建）、log_file_usage（日志文件使用）

**特殊项**：

- character_naming_quality（角色命名质量）：仅展示不计分（DISPLAY_ONLY）。全员 ~76.9% fail，说明 AI 命名倾向是系统性问题。

</details>

<details>
<summary>C. EB5-midtrain 详情</summary>

EB5-midtrain 是一个正在训练中的模型（mid-training checkpoint），其表现反映了模型训练不充分时的典型问题：

- **50% gate fail rate**：24 个样本中 12 个触发 gate——半数连基本输出都无法完成
- **根因**：不会正确使用 write_file 工具，把所有内容以纯文本形式输出在对话消息里，导致评测系统无法检测到章节文件
- **排除 gate 后均分 59.1**：即使"跑通"的样本，质量也仅略高于 ernie（排 gate 后 55.8）
- **MEDIUM 篇幅内容均分仅 17.0**：中篇写作能力几乎为零
- **本报告纳入 EB5 作为弱梯队参照**，但其数据不应与正式发布模型直接比较

</details>
